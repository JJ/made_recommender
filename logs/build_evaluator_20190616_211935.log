2019-06-16 21:19:35,860 | INFO     | Init script: {"random_seed": 0, "source_extended_dataset": "datasets/extended_dataset.csv.bz2"}
2019-06-16 21:19:39,137 | INFO     | Layer sizes: [26273, 883, 29, 1]
2019-06-16 21:20:42,045 | INFO     | Iteration 1, loss = 5.69897820
2019-06-16 21:21:40,471 | INFO     | Iteration 2, loss = 1.17464673
2019-06-16 21:22:40,109 | INFO     | Iteration 3, loss = 0.51393032
2019-06-16 21:23:36,497 | INFO     | Iteration 4, loss = 0.28652275
2019-06-16 21:24:42,038 | INFO     | Iteration 5, loss = 0.19154755
2019-06-16 21:25:48,442 | INFO     | Iteration 6, loss = 0.15933599
2019-06-16 21:26:55,467 | INFO     | Iteration 7, loss = 0.15170130
2019-06-16 21:28:03,659 | INFO     | Iteration 8, loss = 0.15406612
2019-06-16 21:29:16,015 | INFO     | Iteration 9, loss = 0.15384220
2019-06-16 21:30:21,473 | INFO     | Iteration 10, loss = 0.15173540
2019-06-16 21:31:21,767 | INFO     | Iteration 11, loss = 0.13708292
2019-06-16 21:32:36,771 | INFO     | Iteration 12, loss = 0.12760929
2019-06-16 21:33:46,125 | INFO     | Iteration 13, loss = 0.11974019
2019-06-16 21:34:43,203 | INFO     | Iteration 14, loss = 0.10984630
2019-06-16 21:35:39,853 | INFO     | Iteration 15, loss = 0.10681433
2019-06-16 21:36:36,471 | INFO     | Iteration 16, loss = 0.10251998
2019-06-16 21:37:32,981 | INFO     | Iteration 17, loss = 0.09700506
2019-06-16 21:38:29,872 | INFO     | Iteration 18, loss = 0.09102520
2019-06-16 21:39:26,654 | INFO     | Iteration 19, loss = 0.08778920
2019-06-16 21:40:23,321 | INFO     | Iteration 20, loss = 0.08558719
2019-06-16 21:41:19,958 | INFO     | Iteration 21, loss = 0.08363773
2019-06-16 21:42:16,178 | INFO     | Iteration 22, loss = 0.08838583
2019-06-16 21:43:12,557 | INFO     | Iteration 23, loss = 0.08768976
2019-06-16 21:44:08,950 | INFO     | Iteration 24, loss = 0.08426935
2019-06-16 21:45:05,257 | INFO     | Iteration 25, loss = 0.07948309
2019-06-16 21:46:01,774 | INFO     | Iteration 26, loss = 0.07965793
2019-06-16 21:47:01,130 | INFO     | Iteration 27, loss = 0.07760953
2019-06-16 21:48:01,333 | INFO     | Iteration 28, loss = 0.07466120
2019-06-16 21:49:03,096 | INFO     | Iteration 29, loss = 0.07166935
2019-06-16 21:50:08,729 | INFO     | Iteration 30, loss = 0.06846434
2019-06-16 21:51:08,792 | INFO     | Iteration 31, loss = 0.06587681
2019-06-16 21:52:06,479 | INFO     | Iteration 32, loss = 0.06422635
2019-06-16 21:53:03,582 | INFO     | Iteration 33, loss = 0.06355214
2019-06-16 21:54:00,754 | INFO     | Iteration 34, loss = 0.06465154
2019-06-16 21:54:57,690 | INFO     | Iteration 35, loss = 0.06730353
2019-06-16 21:55:58,272 | INFO     | Iteration 36, loss = 0.06850626
2019-06-16 21:57:05,532 | INFO     | Iteration 37, loss = 0.07167046
2019-06-16 21:58:08,304 | INFO     | Iteration 38, loss = 0.06983822
2019-06-16 21:59:07,161 | INFO     | Iteration 39, loss = 0.06695579
2019-06-16 22:00:08,136 | INFO     | Iteration 40, loss = 0.06660669
2019-06-16 22:01:06,594 | INFO     | Iteration 41, loss = 0.06559071
2019-06-16 22:02:06,176 | INFO     | Iteration 42, loss = 0.06340163
2019-06-16 22:03:04,076 | INFO     | Iteration 43, loss = 0.06715073
2019-06-16 22:04:01,845 | INFO     | Iteration 44, loss = 0.06800108
2019-06-16 22:04:59,159 | INFO     | Iteration 45, loss = 0.07070761
2019-06-16 22:05:56,285 | INFO     | Iteration 46, loss = 0.07140960
2019-06-16 22:06:53,276 | INFO     | Iteration 47, loss = 0.06600636
2019-06-16 22:07:49,938 | INFO     | Iteration 48, loss = 0.06469830
2019-06-16 22:08:46,981 | INFO     | Iteration 49, loss = 0.06907019
2019-06-16 22:09:43,624 | INFO     | Iteration 50, loss = 0.06973632
2019-06-16 22:10:40,264 | INFO     | Iteration 51, loss = 0.06516915
2019-06-16 22:11:37,330 | INFO     | Iteration 52, loss = 0.06047957
2019-06-16 22:12:34,102 | INFO     | Iteration 53, loss = 0.05912311
2019-06-16 22:13:30,495 | INFO     | Iteration 54, loss = 0.06071611
2019-06-16 22:14:26,681 | INFO     | Iteration 55, loss = 0.05825691
2019-06-16 22:15:22,612 | INFO     | Iteration 56, loss = 0.05502283
2019-06-16 22:16:18,733 | INFO     | Iteration 57, loss = 0.05353134
2019-06-16 22:17:14,915 | INFO     | Iteration 58, loss = 0.05549666
2019-06-16 22:18:13,524 | INFO     | Iteration 59, loss = 0.05695886
2019-06-16 22:19:12,052 | INFO     | Iteration 60, loss = 0.05427265
2019-06-16 22:20:09,279 | INFO     | Iteration 61, loss = 0.05620715
2019-06-16 22:21:07,856 | INFO     | Iteration 62, loss = 0.06017585
2019-06-16 22:22:07,150 | INFO     | Iteration 63, loss = 0.06073629
2019-06-16 22:23:11,438 | INFO     | Iteration 64, loss = 0.05874190
2019-06-16 22:24:11,773 | INFO     | Iteration 65, loss = 0.05561279
2019-06-16 22:25:09,572 | INFO     | Iteration 66, loss = 0.05586757
2019-06-16 22:26:07,038 | INFO     | Iteration 67, loss = 0.05513409
2019-06-16 22:27:04,590 | INFO     | Iteration 68, loss = 0.05699947
2019-06-16 22:27:04,593 | INFO     | Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
2019-06-16 22:27:06,719 | INFO     | Pickled evaluator path: datasets/evaluator_26273_883_29_1.sav
2019-06-16 22:27:06,720 | INFO     | Finish script: {"Layer sizes": [26273, 883, 29, 1], "Pickled evaluator path": "datasets/evaluator_26273_883_29_1.sav", "total_execution": "01:07:30.859"}
